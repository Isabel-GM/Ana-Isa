{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos las librerías que necesitamos\n",
    "\n",
    "# Tratamiento de datos\n",
    "# -----------------------------------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "# ------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Evaluar linealidad de las relaciones entre las variables\n",
    "# ------------------------------------------------------------------------------\n",
    "from scipy.stats import shapiro, kstest\n",
    "\n",
    "# Configuración\n",
    "# -----------------------------------------------------------------------\n",
    "pd.set_option('display.max_columns', None) # para poder visualizar todas las columnas de los DataFrames\n",
    "\n",
    "# Gestión de los warnings\n",
    "# -----------------------------------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>profile_completeness</th>\n",
       "      <th>essay_word_count</th>\n",
       "      <th>profile_views_last_month</th>\n",
       "      <th>messages_sent_last_week</th>\n",
       "      <th>likes_received</th>\n",
       "      <th>mutual_matches</th>\n",
       "      <th>time_spent_daily</th>\n",
       "      <th>swipe_right_ratio</th>\n",
       "      <th>swipe_right_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>100</td>\n",
       "      <td>450</td>\n",
       "      <td>1176</td>\n",
       "      <td>20</td>\n",
       "      <td>147</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>0.69</td>\n",
       "      <td>Optimistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>60</td>\n",
       "      <td>268</td>\n",
       "      <td>1509</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>32</td>\n",
       "      <td>41</td>\n",
       "      <td>0.56</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>90</td>\n",
       "      <td>856</td>\n",
       "      <td>910</td>\n",
       "      <td>21</td>\n",
       "      <td>221</td>\n",
       "      <td>129</td>\n",
       "      <td>29</td>\n",
       "      <td>0.65</td>\n",
       "      <td>Optimistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>70</td>\n",
       "      <td>75</td>\n",
       "      <td>1344</td>\n",
       "      <td>19</td>\n",
       "      <td>57</td>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>0.61</td>\n",
       "      <td>Optimistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>50</td>\n",
       "      <td>105</td>\n",
       "      <td>1180</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>0.36</td>\n",
       "      <td>Balanced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type               diet  \\\n",
       "0   22     single   m    straight  a little extra  strictly anything   \n",
       "1   35     single   m    straight         average       mostly other   \n",
       "2   38  available   m    straight            thin           anything   \n",
       "3   23     single   m    straight            thin         vegetarian   \n",
       "4   29     single   m    straight        athletic                NaN   \n",
       "\n",
       "     drinks      drugs                          education  \\\n",
       "0  socially      never      working on college/university   \n",
       "1     often  sometimes              working on space camp   \n",
       "2  socially        NaN     graduated from masters program   \n",
       "3  socially        NaN      working on college/university   \n",
       "4  socially      never  graduated from college/university   \n",
       "\n",
       "             ethnicity  height  income                          job  \\\n",
       "0         asian, white    75.0      -1               transportation   \n",
       "1                white    70.0   80000         hospitality / travel   \n",
       "2                  NaN    68.0      -1                          NaN   \n",
       "3                white    71.0   20000                      student   \n",
       "4  asian, black, other    66.0      -1  artistic / musical / writer   \n",
       "\n",
       "        last_online                         location  \\\n",
       "0  2012-06-28-20-30  south san francisco, california   \n",
       "1  2012-06-29-21-41              oakland, california   \n",
       "2  2012-06-27-09-10        san francisco, california   \n",
       "3  2012-06-28-14-22             berkeley, california   \n",
       "4  2012-06-27-21-26        san francisco, california   \n",
       "\n",
       "                                offspring                       pets  \\\n",
       "0  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "1  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "2                                     NaN                   has cats   \n",
       "3                       doesn't want kids                 likes cats   \n",
       "4                                     NaN  likes dogs and likes cats   \n",
       "\n",
       "                                   religion  \\\n",
       "0     agnosticism and very serious about it   \n",
       "1  agnosticism but not too serious about it   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks  profile_completeness  \\\n",
       "0                                            english                   100   \n",
       "1  english (fluently), spanish (poorly), french (...                    60   \n",
       "2                               english, french, c++                    90   \n",
       "3                           english, german (poorly)                    70   \n",
       "4                                            english                    50   \n",
       "\n",
       "   essay_word_count  profile_views_last_month  messages_sent_last_week  \\\n",
       "0               450                      1176                       20   \n",
       "1               268                      1509                        7   \n",
       "2               856                       910                       21   \n",
       "3                75                      1344                       19   \n",
       "4               105                      1180                       12   \n",
       "\n",
       "   likes_received  mutual_matches  time_spent_daily  swipe_right_ratio  \\\n",
       "0             147              39                52               0.69   \n",
       "1              76              32                41               0.56   \n",
       "2             221             129                29               0.65   \n",
       "3              57              15                67               0.61   \n",
       "4              57              25                29               0.36   \n",
       "\n",
       "  swipe_right_label  \n",
       "0        Optimistic  \n",
       "1          Balanced  \n",
       "2        Optimistic  \n",
       "3        Optimistic  \n",
       "4          Balanced  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"okcupid.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El número de filas que tenemos es 59946, y el número de columnas es 30\n"
     ]
    }
   ],
   "source": [
    "# reviso el tamaño del df\n",
    "\n",
    "print(f\"El número de filas que tenemos es {df.shape[0]}, y el número de columnas es {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>32.340290</td>\n",
       "      <td>9.452779</td>\n",
       "      <td>18.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>59943.0</td>\n",
       "      <td>68.295281</td>\n",
       "      <td>3.994803</td>\n",
       "      <td>1.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>68.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>20033.222534</td>\n",
       "      <td>97346.192104</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_completeness</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>81.047776</td>\n",
       "      <td>27.988025</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_word_count</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>356.896106</td>\n",
       "      <td>295.830482</td>\n",
       "      <td>0.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>299.00</td>\n",
       "      <td>481.00</td>\n",
       "      <td>10602.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profile_views_last_month</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>1029.695726</td>\n",
       "      <td>561.287949</td>\n",
       "      <td>50.00</td>\n",
       "      <td>547.00</td>\n",
       "      <td>1033.00</td>\n",
       "      <td>1515.75</td>\n",
       "      <td>1999.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>messages_sent_last_week</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>11.573733</td>\n",
       "      <td>8.537646</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>11.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likes_received</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>111.627031</td>\n",
       "      <td>67.180995</td>\n",
       "      <td>0.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>105.00</td>\n",
       "      <td>144.00</td>\n",
       "      <td>2174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mutual_matches</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>38.718764</td>\n",
       "      <td>30.169834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>53.00</td>\n",
       "      <td>665.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_spent_daily</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>61.770794</td>\n",
       "      <td>20.187392</td>\n",
       "      <td>5.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>75.00</td>\n",
       "      <td>142.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swipe_right_ratio</th>\n",
       "      <td>59946.0</td>\n",
       "      <td>0.635675</td>\n",
       "      <td>0.153326</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            count          mean           std    min     25%  \\\n",
       "age                       59946.0     32.340290      9.452779  18.00   26.00   \n",
       "height                    59943.0     68.295281      3.994803   1.00   66.00   \n",
       "income                    59946.0  20033.222534  97346.192104  -1.00   -1.00   \n",
       "profile_completeness      59946.0     81.047776     27.988025   0.00   70.00   \n",
       "essay_word_count          59946.0    356.896106    295.830482   0.00  159.00   \n",
       "profile_views_last_month  59946.0   1029.695726    561.287949  50.00  547.00   \n",
       "messages_sent_last_week   59946.0     11.573733      8.537646   0.00    4.00   \n",
       "likes_received            59946.0    111.627031     67.180995   0.00   71.00   \n",
       "mutual_matches            59946.0     38.718764     30.169834   0.00   18.00   \n",
       "time_spent_daily          59946.0     61.770794     20.187392   5.00   48.00   \n",
       "swipe_right_ratio         59946.0      0.635675      0.153326   0.05    0.58   \n",
       "\n",
       "                              50%      75%         max  \n",
       "age                         30.00    37.00      110.00  \n",
       "height                      68.00    71.00       95.00  \n",
       "income                      -1.00    -1.00  1000000.00  \n",
       "profile_completeness        90.00   100.00      100.00  \n",
       "essay_word_count           299.00   481.00    10602.00  \n",
       "profile_views_last_month  1033.00  1515.75     1999.00  \n",
       "messages_sent_last_week     11.00    18.00       29.00  \n",
       "likes_received             105.00   144.00     2174.00  \n",
       "mutual_matches              32.00    53.00      665.00  \n",
       "time_spent_daily            62.00    75.00      142.00  \n",
       "swipe_right_ratio            0.68     0.74        0.95  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 30 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   age                       59946 non-null  int64  \n",
      " 1   status                    59946 non-null  object \n",
      " 2   sex                       59946 non-null  object \n",
      " 3   orientation               59946 non-null  object \n",
      " 4   body_type                 54650 non-null  object \n",
      " 5   diet                      35551 non-null  object \n",
      " 6   drinks                    56961 non-null  object \n",
      " 7   drugs                     45866 non-null  object \n",
      " 8   education                 53318 non-null  object \n",
      " 9   ethnicity                 54266 non-null  object \n",
      " 10  height                    59943 non-null  float64\n",
      " 11  income                    59946 non-null  int64  \n",
      " 12  job                       51748 non-null  object \n",
      " 13  last_online               59946 non-null  object \n",
      " 14  location                  59946 non-null  object \n",
      " 15  offspring                 24385 non-null  object \n",
      " 16  pets                      40025 non-null  object \n",
      " 17  religion                  39720 non-null  object \n",
      " 18  sign                      48890 non-null  object \n",
      " 19  smokes                    54434 non-null  object \n",
      " 20  speaks                    59896 non-null  object \n",
      " 21  profile_completeness      59946 non-null  int64  \n",
      " 22  essay_word_count          59946 non-null  int64  \n",
      " 23  profile_views_last_month  59946 non-null  int64  \n",
      " 24  messages_sent_last_week   59946 non-null  int64  \n",
      " 25  likes_received            59946 non-null  int64  \n",
      " 26  mutual_matches            59946 non-null  int64  \n",
      " 27  time_spent_daily          59946 non-null  int64  \n",
      " 28  swipe_right_ratio         59946 non-null  float64\n",
      " 29  swipe_right_label         59946 non-null  object \n",
      "dtypes: float64(2), int64(9), object(19)\n",
      "memory usage: 13.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 19 columnas categóricas:\n",
      "['status', 'sex', 'orientation', 'body_type', 'diet', 'drinks', 'drugs', 'education', 'ethnicity', 'job', 'last_online', 'location', 'offspring', 'pets', 'religion', 'sign', 'smokes', 'speaks', 'swipe_right_label']\n"
     ]
    }
   ],
   "source": [
    "# Detecto las columnas objects:\n",
    "\n",
    "col_objects = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "print(f\"Hay {len(col_objects)} columnas categóricas:\")\n",
    "print(col_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 11 columnas numericas:\n",
      "['age', 'height', 'income', 'profile_completeness', 'essay_word_count', 'profile_views_last_month', 'messages_sent_last_week', 'likes_received', 'mutual_matches', 'time_spent_daily', 'swipe_right_ratio']\n"
     ]
    }
   ],
   "source": [
    "# Detecto las columnas numericas:\n",
    "\n",
    "col_num = df.select_dtypes(exclude='object').columns.tolist()\n",
    "\n",
    "print(f\"Hay {len(col_num)} columnas numericas:\")\n",
    "print(col_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                            54\n",
       "status                          5\n",
       "sex                             2\n",
       "orientation                     3\n",
       "body_type                      12\n",
       "diet                           18\n",
       "drinks                          6\n",
       "drugs                           3\n",
       "education                      32\n",
       "ethnicity                     217\n",
       "height                         60\n",
       "income                         13\n",
       "job                            21\n",
       "last_online                 30123\n",
       "location                      199\n",
       "offspring                      15\n",
       "pets                           15\n",
       "religion                       45\n",
       "sign                           48\n",
       "smokes                          5\n",
       "speaks                       7647\n",
       "profile_completeness           11\n",
       "essay_word_count             1786\n",
       "profile_views_last_month     1950\n",
       "messages_sent_last_week        30\n",
       "likes_received                541\n",
       "mutual_matches                270\n",
       "time_spent_daily              134\n",
       "swipe_right_ratio              91\n",
       "swipe_right_label               3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna age tiene estos valores únicos:\n",
      "[ 22  35  38  23  29  32  31  24  37  28  30  39  33  26  27  20  25  40\n",
      "  36  21  34  43  46  41  42  45  18  55  50  59  44  48  54  51  62  52\n",
      "  19  58  66  53  63  47  49  61  60  57  56  65  64  68 110  69  67 109]\n",
      "----------------------------\n",
      "La columna status tiene estos valores únicos:\n",
      "['single' 'available' 'seeing someone' 'married' 'unknown']\n",
      "----------------------------\n",
      "La columna sex tiene estos valores únicos:\n",
      "['m' 'f']\n",
      "----------------------------\n",
      "La columna orientation tiene estos valores únicos:\n",
      "['straight' 'bisexual' 'gay']\n",
      "----------------------------\n",
      "La columna body_type tiene estos valores únicos:\n",
      "['a little extra' 'average' 'thin' 'athletic' 'fit' nan 'skinny' 'curvy'\n",
      " 'full figured' 'jacked' 'rather not say' 'used up' 'overweight']\n",
      "----------------------------\n",
      "La columna diet tiene estos valores únicos:\n",
      "['strictly anything' 'mostly other' 'anything' 'vegetarian' nan\n",
      " 'mostly anything' 'mostly vegetarian' 'strictly vegan'\n",
      " 'strictly vegetarian' 'mostly vegan' 'strictly other' 'mostly halal'\n",
      " 'other' 'vegan' 'mostly kosher' 'strictly halal' 'halal'\n",
      " 'strictly kosher' 'kosher']\n",
      "----------------------------\n",
      "La columna drinks tiene estos valores únicos:\n",
      "['socially' 'often' 'not at all' 'rarely' nan 'very often' 'desperately']\n",
      "----------------------------\n",
      "La columna drugs tiene estos valores únicos:\n",
      "['never' 'sometimes' nan 'often']\n",
      "----------------------------\n",
      "La columna education tiene estos valores únicos:\n",
      "['working on college/university' 'working on space camp'\n",
      " 'graduated from masters program' 'graduated from college/university'\n",
      " 'working on two-year college' nan 'graduated from high school'\n",
      " 'working on masters program' 'graduated from space camp'\n",
      " 'college/university' 'dropped out of space camp'\n",
      " 'graduated from ph.d program' 'graduated from law school'\n",
      " 'working on ph.d program' 'two-year college'\n",
      " 'graduated from two-year college' 'working on med school'\n",
      " 'dropped out of college/university' 'space camp'\n",
      " 'graduated from med school' 'dropped out of high school'\n",
      " 'working on high school' 'masters program' 'dropped out of ph.d program'\n",
      " 'dropped out of two-year college' 'dropped out of med school'\n",
      " 'high school' 'working on law school' 'law school'\n",
      " 'dropped out of masters program' 'ph.d program'\n",
      " 'dropped out of law school' 'med school']\n",
      "----------------------------\n",
      "La columna ethnicity tiene estos valores únicos:\n",
      "['asian, white' 'white' nan 'asian, black, other' 'white, other'\n",
      " 'hispanic / latin, white' 'hispanic / latin' 'pacific islander, white'\n",
      " 'asian' 'black, white' 'pacific islander' 'asian, native american'\n",
      " 'asian, pacific islander' 'black, native american, white'\n",
      " 'middle eastern, other' 'native american, white' 'indian' 'black'\n",
      " 'black, native american, hispanic / latin, other'\n",
      " 'black, native american, hispanic / latin'\n",
      " 'asian, black, pacific islander'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other'\n",
      " 'other' 'hispanic / latin, other' 'asian, black' 'middle eastern, white'\n",
      " 'native american, white, other' 'black, native american'\n",
      " 'black, white, other' 'hispanic / latin, white, other' 'middle eastern'\n",
      " 'black, other' 'native american, hispanic / latin, white' 'black, indian'\n",
      " 'indian, white, other' 'middle eastern, indian, other'\n",
      " 'black, native american, hispanic / latin, white, other'\n",
      " 'pacific islander, hispanic / latin' 'black, hispanic / latin, white'\n",
      " 'native american' 'indian, white' 'asian, white, other'\n",
      " 'black, hispanic / latin' 'asian, hispanic / latin, white'\n",
      " 'middle eastern, hispanic / latin'\n",
      " 'asian, black, native american, pacific islander, white'\n",
      " 'middle eastern, indian' 'asian, indian' 'pacific islander, other'\n",
      " 'black, native american, white, other' 'black, pacific islander'\n",
      " 'middle eastern, native american, white'\n",
      " 'asian, native american, white, other'\n",
      " 'pacific islander, hispanic / latin, white' 'indian, other'\n",
      " 'asian, pacific islander, other' 'black, hispanic / latin, other'\n",
      " 'asian, black, native american'\n",
      " 'black, native american, hispanic / latin, white'\n",
      " 'native american, hispanic / latin' 'indian, hispanic / latin'\n",
      " 'native american, pacific islander'\n",
      " 'asian, black, native american, hispanic / latin, white'\n",
      " 'asian, black, white'\n",
      " 'asian, black, native american, pacific islander, other'\n",
      " 'middle eastern, hispanic / latin, white'\n",
      " 'asian, pacific islander, white'\n",
      " 'asian, native american, hispanic / latin, white, other'\n",
      " 'asian, hispanic / latin' 'asian, pacific islander, white, other'\n",
      " 'middle eastern, white, other'\n",
      " 'asian, pacific islander, hispanic / latin'\n",
      " 'black, native american, indian, other'\n",
      " 'native american, hispanic / latin, white, other'\n",
      " 'black, native american, other' 'asian, other'\n",
      " 'middle eastern, hispanic / latin, other'\n",
      " 'pacific islander, hispanic / latin, white, other'\n",
      " 'asian, black, hispanic / latin'\n",
      " 'asian, pacific islander, hispanic / latin, white'\n",
      " 'asian, black, native american, white'\n",
      " 'asian, middle eastern, white, other'\n",
      " 'native american, pacific islander, hispanic / latin'\n",
      " 'asian, native american, white'\n",
      " 'native american, pacific islander, hispanic / latin, white, other'\n",
      " 'indian, pacific islander' 'asian, middle eastern, black'\n",
      " 'asian, middle eastern, indian' 'asian, middle eastern, white'\n",
      " 'pacific islander, white, other'\n",
      " 'black, pacific islander, hispanic / latin' 'asian, middle eastern'\n",
      " 'asian, hispanic / latin, other'\n",
      " 'middle eastern, black, native american, indian, white, other'\n",
      " 'middle eastern, pacific islander, other' 'middle eastern, black'\n",
      " 'asian, indian, pacific islander'\n",
      " 'black, native american, pacific islander' 'native american, indian'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white'\n",
      " 'black, indian, other'\n",
      " 'asian, middle eastern, indian, hispanic / latin, white, other'\n",
      " 'middle eastern, black, white' 'asian, hispanic / latin, white, other'\n",
      " 'native american, hispanic / latin, other'\n",
      " 'middle eastern, black, pacific islander, white'\n",
      " 'asian, black, native american, hispanic / latin'\n",
      " 'native american, other' 'black, indian, white'\n",
      " 'asian, native american, hispanic / latin, white'\n",
      " 'black, native american, indian, white'\n",
      " 'middle eastern, black, indian, pacific islander, hispanic / latin, white'\n",
      " 'middle eastern, hispanic / latin, white, other'\n",
      " 'asian, black, native american, other'\n",
      " 'native american, pacific islander, hispanic / latin, white'\n",
      " 'asian, indian, other'\n",
      " 'middle eastern, native american, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, black, pacific islander, hispanic / latin, white'\n",
      " 'black, native american, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, native american, hispanic / latin, white'\n",
      " 'asian, middle eastern, black, native american, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, indian, white' 'native american, pacific islander, white, other'\n",
      " 'middle eastern, black, native american, indian, pacific islander, hispanic / latin, white'\n",
      " 'asian, middle eastern, other' 'middle eastern, pacific islander'\n",
      " 'asian, black, hispanic / latin, other'\n",
      " 'asian, middle eastern, black, native american, hispanic / latin, white'\n",
      " 'middle eastern, black, hispanic / latin'\n",
      " 'black, pacific islander, white'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, other'\n",
      " 'middle eastern, black, native american, indian, hispanic / latin, white'\n",
      " 'asian, pacific islander, hispanic / latin, white, other'\n",
      " 'middle eastern, indian, white' 'asian, indian, white, other'\n",
      " 'middle eastern, black, native american, white, other'\n",
      " 'black, native american, pacific islander, other'\n",
      " 'middle eastern, black, native american, white'\n",
      " 'asian, indian, pacific islander, other'\n",
      " 'asian, black, native american, white, other'\n",
      " 'black, indian, hispanic / latin, white'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, white'\n",
      " 'asian, black, pacific islander, hispanic / latin'\n",
      " 'middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, black, native american, indian'\n",
      " 'asian, black, indian, hispanic / latin, other'\n",
      " 'indian, hispanic / latin, other' 'asian, indian, hispanic / latin'\n",
      " 'asian, native american, pacific islander, white, other'\n",
      " 'asian, black, native american, indian, hispanic / latin, white, other'\n",
      " 'asian, indian, hispanic / latin, white'\n",
      " 'pacific islander, hispanic / latin, other'\n",
      " 'asian, indian, pacific islander, hispanic / latin, white, other'\n",
      " 'indian, hispanic / latin, white'\n",
      " 'asian, native american, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, pacific islander, hispanic / latin, other'\n",
      " 'asian, black, hispanic / latin, white, other'\n",
      " 'black, indian, hispanic / latin'\n",
      " 'middle eastern, black, native american, hispanic / latin, white'\n",
      " 'black, pacific islander, other'\n",
      " 'black, native american, pacific islander, white'\n",
      " 'asian, black, native american, pacific islander'\n",
      " 'asian, indian, hispanic / latin, other'\n",
      " 'middle eastern, native american'\n",
      " 'middle eastern, native american, hispanic / latin'\n",
      " 'black, hispanic / latin, white, other'\n",
      " 'asian, native american, pacific islander, hispanic / latin, white'\n",
      " 'asian, native american, hispanic / latin'\n",
      " 'black, native american, indian, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, hispanic / latin, white'\n",
      " 'black, native american, pacific islander, white, other'\n",
      " 'native american, indian, pacific islander, hispanic / latin'\n",
      " 'black, indian, white, other'\n",
      " 'asian, middle eastern, native american, pacific islander, hispanic / latin, white, other'\n",
      " 'native american, pacific islander, white'\n",
      " 'middle eastern, indian, white, other' 'asian, black, white, other'\n",
      " 'middle eastern, native american, hispanic / latin, white'\n",
      " 'indian, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, black, pacific islander'\n",
      " 'asian, middle eastern, black, indian, pacific islander, hispanic / latin, white'\n",
      " 'asian, middle eastern, indian, other'\n",
      " 'asian, middle eastern, black, white, other'\n",
      " 'black, native american, pacific islander, hispanic / latin, white'\n",
      " 'black, native american, indian, pacific islander, hispanic / latin'\n",
      " 'asian, black, pacific islander, white'\n",
      " 'middle eastern, pacific islander, hispanic / latin'\n",
      " 'black, native american, indian, white, other'\n",
      " 'asian, black, hispanic / latin, white'\n",
      " 'asian, black, native american, indian, pacific islander, white'\n",
      " 'asian, black, native american, indian, pacific islander, hispanic / latin'\n",
      " 'asian, middle eastern, hispanic / latin, white, other'\n",
      " 'middle eastern, black, native american, indian'\n",
      " 'asian, native american, pacific islander'\n",
      " 'asian, black, native american, pacific islander, white, other'\n",
      " 'asian, middle eastern, hispanic / latin'\n",
      " 'asian, black, pacific islander, other'\n",
      " 'asian, native american, indian, pacific islander, hispanic / latin, white'\n",
      " 'middle eastern, native american, white, other'\n",
      " 'asian, native american, hispanic / latin, other'\n",
      " 'native american, indian, white'\n",
      " 'black, native american, pacific islander, hispanic / latin'\n",
      " 'asian, native american, pacific islander, white'\n",
      " 'black, native american, indian'\n",
      " 'indian, pacific islander, hispanic / latin, white'\n",
      " 'asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin'\n",
      " 'asian, middle eastern, indian, hispanic / latin'\n",
      " 'asian, middle eastern, native american, pacific islander, other'\n",
      " 'black, native american, indian, pacific islander'\n",
      " 'asian, middle eastern, native american, pacific islander, white, other'\n",
      " 'asian, native american, other' 'middle eastern, black, other'\n",
      " 'asian, black, pacific islander, hispanic / latin, white'\n",
      " 'asian, middle eastern, native american, indian, pacific islander, hispanic / latin, white'\n",
      " 'asian, native american, indian, pacific islander, hispanic / latin, white, other'\n",
      " 'asian, middle eastern, black, pacific islander, hispanic / latin'\n",
      " 'asian, black, pacific islander, white, other' 'asian, black, indian']\n",
      "----------------------------\n",
      "La columna height tiene estos valores únicos:\n",
      "[75. 70. 68. 71. 66. 67. 65. 72. 62. 64. 69. 73. 74. 60. 63. 76. 61. 78.\n",
      " 79. 59. 80. 91. 83. 77. 58. 56. 95. 57. 87. 81. 36. 43. 52. 55. 53. 93.\n",
      "  8. 54. 82.  3. 86. 42. 84. 94. 50.  6. 47. 49. 48. 90. 88. nan 37.  9.\n",
      " 51.  1. 92. 26. 85. 89.  4.]\n",
      "----------------------------\n",
      "La columna income tiene estos valores únicos:\n",
      "[     -1   80000   20000   40000   30000   50000   60000 1000000  150000\n",
      "  100000  500000   70000  250000]\n",
      "----------------------------\n",
      "La columna job tiene estos valores únicos:\n",
      "['transportation' 'hospitality / travel' nan 'student'\n",
      " 'artistic / musical / writer' 'computer / hardware / software'\n",
      " 'banking / financial / real estate' 'entertainment / media'\n",
      " 'sales / marketing / biz dev' 'other' 'medicine / health'\n",
      " 'science / tech / engineering' 'executive / management'\n",
      " 'education / academia' 'clerical / administrative'\n",
      " 'construction / craftsmanship' 'rather not say' 'political / government'\n",
      " 'law / legal services' 'unemployed' 'military' 'retired']\n",
      "----------------------------\n",
      "La columna last_online tiene estos valores únicos:\n",
      "['2012-06-28-20-30' '2012-06-29-21-41' '2012-06-27-09-10' ...\n",
      " '2012-06-02-08-16' '2012-02-17-20-44' '2012-06-14-16-51']\n",
      "----------------------------\n",
      "La columna location tiene estos valores únicos:\n",
      "['south san francisco, california' 'oakland, california'\n",
      " 'san francisco, california' 'berkeley, california'\n",
      " 'belvedere tiburon, california' 'san mateo, california'\n",
      " 'daly city, california' 'san leandro, california' 'atherton, california'\n",
      " 'san rafael, california' 'walnut creek, california'\n",
      " 'menlo park, california' 'belmont, california' 'san jose, california'\n",
      " 'palo alto, california' 'emeryville, california' 'el granada, california'\n",
      " 'castro valley, california' 'fairfax, california'\n",
      " 'mountain view, california' 'burlingame, california'\n",
      " 'martinez, california' 'pleasant hill, california' 'hayward, california'\n",
      " 'alameda, california' 'vallejo, california' 'benicia, california'\n",
      " 'el cerrito, california' 'mill valley, california' 'richmond, california'\n",
      " 'redwood city, california' 'el sobrante, california'\n",
      " 'stanford, california' 'san pablo, california' 'novato, california'\n",
      " 'pacifica, california' 'lafayette, california'\n",
      " 'half moon bay, california' 'fremont, california' 'orinda, california'\n",
      " 'san anselmo, california' 'corte madera, california' 'albany, california'\n",
      " 'san carlos, california' 'san lorenzo, california'\n",
      " 'foster city, california' 'hercules, california' 'santa cruz, california'\n",
      " 'bolinas, california' 'sausalito, california' 'millbrae, california'\n",
      " 'larkspur, california' 'moraga, california' 'san bruno, california'\n",
      " 'petaluma, california' 'pinole, california' 'san geronimo, california'\n",
      " 'crockett, california' 'boulder, colorado' 'brisbane, california'\n",
      " 'freedom, california' 'montara, california' 'green brae, california'\n",
      " 'woodside, california' 'new york, new york' 'ross, california'\n",
      " 'east palo alto, california' 'san quentin, california' 'portland, oregon'\n",
      " 'rodeo, california' 'hacienda heights, california' 'woodacre, california'\n",
      " 'westlake, california' 'riverside, california' 'rohnert park, california'\n",
      " 'sacramento, california' 'point richmond, california'\n",
      " 'san diego, california' 'canyon country, california' 'tucson, arizona'\n",
      " 'honolulu, hawaii' 'billings, montana' 'west oakland, california'\n",
      " 'kentfield, california' 'milwaukee, wisconsin' 'woodbridge, virginia'\n",
      " 'glencove, california' 'tiburon, california' 'madrid, spain'\n",
      " 'las vegas, nevada' 'peoria, illinois' 'santa monica, california'\n",
      " 'bellwood, illinois' 'los angeles, california' 'moss beach, california'\n",
      " 'nha trang, vietnam' 'hillsborough, california' 'olema, california'\n",
      " 'union city, california' 'colma, california' 'cork, ireland'\n",
      " 'new orleans, louisiana' 'kensington, california'\n",
      " 'redwood shores, california' 'utica, michigan' 'brea, california'\n",
      " 'lagunitas, california' 'stinson beach, california'\n",
      " 'santa clara, california' 'studio city, california' 'concord, california'\n",
      " 'piedmont, california' 'grand rapids, michigan' 'seaside, california'\n",
      " 'leander, texas' 'forest knolls, california' 'edinburgh, united kingdom'\n",
      " 'magalia, california' 'london, united kingdom' 'astoria, new york'\n",
      " 'chicago, illinois' 'orange, california' 'south wellfleet, massachusetts'\n",
      " 'bayshore, california' 'asheville, north carolina'\n",
      " 'los gatos, california' 'boise, idaho' 'islip terrace, new york'\n",
      " 'sunnyvale, california' 'cambridge, massachusetts' 'lake orion, michigan'\n",
      " 'ozone park, new york' 'jackson, mississippi' 'ashland, california'\n",
      " 'south orange, new jersey' 'fort lauderdale, florida'\n",
      " 'minneapolis, minnesota' 'pasadena, california' 'atlanta, georgia'\n",
      " 'salt lake city, utah' 'arcadia, california' 'milpitas, california'\n",
      " 'san antonio, texas' 'port costa, california' 'nicasio, california'\n",
      " 'livingston, california' 'bellingham, washington' 'crowley, texas'\n",
      " 'boston, massachusetts' 'longwood, florida' 'fayetteville, west virginia'\n",
      " 'granite bay, california' 'isla vista, california' 'hilarita, california'\n",
      " 'campbell, california' 'stratford, connecticut' 'santa ana, california'\n",
      " 'santa rosa, california' 'kula, hawaii' 'murfreesboro, tennessee'\n",
      " 'brooklyn, new york' 'north hollywood, california'\n",
      " 'nevada city, california' 'providence, rhode island'\n",
      " 'stockton, california' 'marin city, california'\n",
      " 'washington, district of columbia' 'waterford, california'\n",
      " 'vancouver, british columbia, canada' 'muir beach, california'\n",
      " 'pacheco, california' 'irvine, california' 'kansas city, missouri'\n",
      " 'kassel, germany' 'canyon, california' 'philadelphia, pennsylvania'\n",
      " 'oceanview, california' 'long beach, new york' 'amsterdam, netherlands'\n",
      " 'taunton, massachusetts' 'napa, california' 'austin, texas'\n",
      " 'san luis obispo, california' 'modesto, california'\n",
      " 'bonaduz, switzerland' 'costa mesa, california' 'guadalajara, mexico'\n",
      " 'oakley, california' 'columbus, ohio' 'chico, california'\n",
      " 'south lake tahoe, california' 'vacaville, california' 'miami, florida'\n",
      " 'long beach, california' 'denver, colorado' 'seattle, washington'\n",
      " 'cincinnati, ohio' 'phoenix, arizona' 'rochester, michigan']\n",
      "----------------------------\n",
      "La columna offspring tiene estos valores únicos:\n",
      "[\"doesn't have kids, but might want them\" nan \"doesn't want kids\"\n",
      " \"doesn't have kids, but wants them\" \"doesn't have kids\" 'wants kids'\n",
      " 'has a kid' 'has kids' \"doesn't have kids, and doesn't want any\"\n",
      " \"has kids, but doesn't want more\" \"has a kid, but doesn't want more\"\n",
      " 'has a kid, and wants more' 'has kids, and might want more'\n",
      " 'might want kids' 'has a kid, and might want more'\n",
      " 'has kids, and wants more']\n",
      "----------------------------\n",
      "La columna pets tiene estos valores únicos:\n",
      "['likes dogs and likes cats' 'has cats' 'likes cats' nan\n",
      " 'has dogs and likes cats' 'likes dogs and has cats'\n",
      " 'likes dogs and dislikes cats' 'has dogs' 'has dogs and dislikes cats'\n",
      " 'likes dogs' 'has dogs and has cats' 'dislikes dogs and has cats'\n",
      " 'dislikes dogs and dislikes cats' 'dislikes cats'\n",
      " 'dislikes dogs and likes cats' 'dislikes dogs']\n",
      "----------------------------\n",
      "La columna religion tiene estos valores únicos:\n",
      "['agnosticism and very serious about it'\n",
      " 'agnosticism but not too serious about it' nan 'atheism' 'christianity'\n",
      " 'christianity but not too serious about it'\n",
      " 'atheism and laughing about it' 'christianity and very serious about it'\n",
      " 'other' 'catholicism' 'catholicism but not too serious about it'\n",
      " 'catholicism and somewhat serious about it'\n",
      " 'agnosticism and somewhat serious about it'\n",
      " 'catholicism and laughing about it' 'agnosticism and laughing about it'\n",
      " 'agnosticism' 'atheism and somewhat serious about it'\n",
      " 'buddhism but not too serious about it'\n",
      " 'other but not too serious about it' 'buddhism'\n",
      " 'other and laughing about it' 'judaism but not too serious about it'\n",
      " 'buddhism and laughing about it' 'other and somewhat serious about it'\n",
      " 'other and very serious about it' 'hinduism but not too serious about it'\n",
      " 'atheism but not too serious about it' 'judaism'\n",
      " 'christianity and somewhat serious about it'\n",
      " 'hinduism and very serious about it' 'atheism and very serious about it'\n",
      " 'judaism and laughing about it' 'christianity and laughing about it'\n",
      " 'hinduism and laughing about it' 'buddhism and somewhat serious about it'\n",
      " 'islam and very serious about it' 'islam' 'hinduism'\n",
      " 'judaism and somewhat serious about it'\n",
      " 'catholicism and very serious about it'\n",
      " 'judaism and very serious about it'\n",
      " 'hinduism and somewhat serious about it'\n",
      " 'islam but not too serious about it' 'buddhism and very serious about it'\n",
      " 'islam and laughing about it' 'islam and somewhat serious about it']\n",
      "----------------------------\n",
      "La columna sign tiene estos valores únicos:\n",
      "['gemini' 'cancer' 'pisces but it doesn&rsquo;t matter' 'pisces'\n",
      " 'aquarius' 'taurus' 'virgo' 'sagittarius'\n",
      " 'gemini but it doesn&rsquo;t matter' 'cancer but it doesn&rsquo;t matter'\n",
      " 'leo but it doesn&rsquo;t matter' nan\n",
      " 'aquarius but it doesn&rsquo;t matter'\n",
      " 'aries and it&rsquo;s fun to think about'\n",
      " 'libra but it doesn&rsquo;t matter'\n",
      " 'pisces and it&rsquo;s fun to think about' 'libra'\n",
      " 'taurus but it doesn&rsquo;t matter'\n",
      " 'sagittarius but it doesn&rsquo;t matter' 'scorpio and it matters a lot'\n",
      " 'gemini and it&rsquo;s fun to think about'\n",
      " 'leo and it&rsquo;s fun to think about'\n",
      " 'cancer and it&rsquo;s fun to think about'\n",
      " 'libra and it&rsquo;s fun to think about'\n",
      " 'aquarius and it&rsquo;s fun to think about'\n",
      " 'virgo but it doesn&rsquo;t matter'\n",
      " 'scorpio and it&rsquo;s fun to think about'\n",
      " 'capricorn but it doesn&rsquo;t matter' 'scorpio'\n",
      " 'capricorn and it&rsquo;s fun to think about' 'leo'\n",
      " 'aries but it doesn&rsquo;t matter' 'aries'\n",
      " 'scorpio but it doesn&rsquo;t matter'\n",
      " 'sagittarius and it&rsquo;s fun to think about'\n",
      " 'libra and it matters a lot' 'taurus and it&rsquo;s fun to think about'\n",
      " 'leo and it matters a lot' 'virgo and it&rsquo;s fun to think about'\n",
      " 'cancer and it matters a lot' 'capricorn' 'pisces and it matters a lot'\n",
      " 'aries and it matters a lot' 'capricorn and it matters a lot'\n",
      " 'aquarius and it matters a lot' 'sagittarius and it matters a lot'\n",
      " 'gemini and it matters a lot' 'taurus and it matters a lot'\n",
      " 'virgo and it matters a lot']\n",
      "----------------------------\n",
      "La columna smokes tiene estos valores únicos:\n",
      "['sometimes' 'no' nan 'when drinking' 'yes' 'trying to quit']\n",
      "----------------------------\n",
      "La columna speaks tiene estos valores únicos:\n",
      "['english' 'english (fluently), spanish (poorly), french (poorly)'\n",
      " 'english, french, c++' ...\n",
      " 'english (fluently), hindi (poorly), french (poorly), tamil (okay), spanish (poorly)'\n",
      " 'english (fluently), french (poorly), japanese (poorly), latin (poorly)'\n",
      " 'english (fluently), french, farsi']\n",
      "----------------------------\n",
      "La columna profile_completeness tiene estos valores únicos:\n",
      "[100  60  90  70  50  10   0  80  40  20  30]\n",
      "----------------------------\n",
      "La columna essay_word_count tiene estos valores únicos:\n",
      "[ 450  268  856 ... 1387 1522 1330]\n",
      "----------------------------\n",
      "La columna profile_views_last_month tiene estos valores únicos:\n",
      "[1176 1509  910 ... 1914 1380 1134]\n",
      "----------------------------\n",
      "La columna messages_sent_last_week tiene estos valores únicos:\n",
      "[20  7 21 19 12 23 25  9 18 13  3  5  0 14 22 16 15 28  8 29 17 10  1 26\n",
      " 24  2  6 27  4 11]\n",
      "----------------------------\n",
      "La columna likes_received tiene estos valores únicos:\n",
      "[ 147   76  221   57  137  113   59  109  126  202  215    4   14  127\n",
      "   68  201  193  128  157   85   72  119  142  171  230  165   88  232\n",
      "  152   51  124   92  214  156   61  183  141  305  275  106   56  306\n",
      "  169   55   62  172    2  132    0   77   29  107   87  145   17  103\n",
      "   86  159  150   36  247  244   98  131  140  116  210  121   69  176\n",
      "  255   15  174  101   93   10  144  212   74  163  192   78  175  112\n",
      "  208   75   64  120   99  161  233   66   84  187  196   65   58  173\n",
      "  164  125  274   38  191   23   60    7   32  211   54   80   79  276\n",
      "  158  185   33  114  198   90  110   48   41   28  102  136   95  397\n",
      "   91  181   11  104   83  118   39   24  148  135  146   71   73  134\n",
      "  224  280   46  204   53   96  189  129  160    1  154  269  153   82\n",
      "  299   63   81  264  195  133    8  143   47  184  167  213  235  180\n",
      "  245  115   18   40  111  228  254  117   89   34  234  108  138  130\n",
      "  122   25  151  252  265   70  543  412    3   27  236   97  186  205\n",
      "  139  350   43  493    6    5   16  227  166   37  100   13   35  178\n",
      "  197  203   21   94  149  344  285  105   49  427  394  123  209  240\n",
      "  155   19  437  278  216  170  179  242  272   30   12   20  260  162\n",
      "  168  286  258  182  383  261   67   52  199  219    9  626  207   50\n",
      "  273  217  231  279  282  226   44  362  188  346  239   22   42  339\n",
      "  334  223  259  267  229  523  454  373  194  391  177  474  321  304\n",
      "   45   31  262  360  347  333  386  289  379   26  266  246  364  190\n",
      "  312  357  419  248  243  369  307  316  302  411  263  241  329  404\n",
      "  220  225  222  622  694  323  218  293  361  237  353  506  355  498\n",
      "  390  409  337  311  270  206  354  315  253  251  200  406  294  309\n",
      "  238  257  332  283  249  271  401  387  459  288  392  318  277  298\n",
      "  335  368  457  521  439  429  313  341  314  250  426  300  287  290\n",
      "  336  551  385  416  281  291  317  256  376  319  689  375  545  372\n",
      "  326  670  348  322  366  435  352  340  539  297  483  381  268  496\n",
      "  292  516  991  931  672  484  351  310  284  295  325  343  446  374\n",
      "  377  345  456  370  549  382  399  371  405  557  467  923  378  330\n",
      "  303  398  485  338  358 1040  327  328  395  331  413  442  535  301\n",
      "  342  464  696  468  473  504  296  488  458  389  552  564  408  400\n",
      "  424  384  857  453  423  508  501  499  356  363  444  414 1527  393\n",
      "  581  367  403  365  465  475  466  421  359  415  445  447  723  463\n",
      "  512  479  500  537 2174  320  422  934  597  431  425  540  482  324\n",
      "  536  625  434  438  451  380  420  449  604  534  550  461  863  478\n",
      "  410  308  529  440  349  455  582  471  388  417  448  402  472  559\n",
      "  443  520  585  956  598  611  396  542  530  555  450  565  491  522\n",
      "  576  476  600  741  480  578  627  418  852]\n",
      "----------------------------\n",
      "La columna mutual_matches tiene estos valores únicos:\n",
      "[ 39  32 129  15  25  23  59  30  22  18  33 117   1   6  43  36  66 103\n",
      "  20  29  63  72  93  27  60  67  55  14  70  21  31  92 142  53  28   0\n",
      "  13   9  46   8  11  51  37  17 125  80  89  40  19  61 119   7  76  90\n",
      "  82   3   2  52  34 124  68 100  42  50  16  10  84  94  35 140  81  79\n",
      "  86  47  49  64  73  56  12  44  83  38  62  95  54  45  24  48 137  57\n",
      " 167  26 108  69  41  78   5  58 122 105 102 220 241  87  88  77 229 141\n",
      " 114 146  99 218 118 201 101 104  65  98 113  75 139 138   4 302 123 106\n",
      " 127 132 135 136  91 109  74 207 143 205 111  71 154 269 191 227 107  96\n",
      " 159 209 110 217 234 128  85  97 169 173 130 266 112 155 133 121 298 185\n",
      " 120 198 116 147 115 181 222 267 170 134 200 161 163 192 172 230 213 228\n",
      " 168 151 215 131 148 126 296 394 182 210 179 158 153 175 409 145 157 165\n",
      " 504 160 180 236 174 214 184 206 149 186 235 190 212 144 166 178 526 193\n",
      " 189 152 150 224 356 156 183 285 195 223 231 244 335 242 176 199 197 171\n",
      " 203 262 219 187 261 381 216 237 238 665 162 325 202 221 260 164 225 280\n",
      " 248 243 246 318 281 204 188 211 523 257 345 251 253 282 239 312 272 250]\n",
      "----------------------------\n",
      "La columna time_spent_daily tiene estos valores únicos:\n",
      "[ 52  41  29  67  68 110  69 108  87  42  71  83  36  37  81  14  76  66\n",
      "  90  91  63  30  53  64  45  80  19 109  74  59  79  35  10  73  56  49\n",
      "  26  43 102  54  25  51  46  86  55  82  60  77  98  70  94  34  65  99\n",
      "  13  89  58  47  27  96  88  78  40  62  23  50  39  57  93  48  31  44\n",
      "  75  28  61  72  32   9  95  21  38 105  12 140  18  97 100  84 104  85\n",
      " 117 101  33   5 118 116  17 103  22  24 106  92  20 111 114  16 107 121\n",
      " 123 122 126 113 112   7 134  15 120   8  11 115   6 119 127 139 128 124\n",
      " 129 125 130 131 135 138 141 142]\n",
      "----------------------------\n",
      "La columna swipe_right_ratio tiene estos valores únicos:\n",
      "[0.69 0.56 0.65 0.61 0.36 0.71 0.82 0.83 0.38 0.13 0.58 0.62 0.6  0.76\n",
      " 0.73 0.48 0.63 0.72 0.55 0.47 0.49 0.27 0.9  0.53 0.41 0.66 0.8  0.37\n",
      " 0.78 0.17 0.19 0.79 0.42 0.64 0.31 0.7  0.24 0.74 0.5  0.52 0.85 0.51\n",
      " 0.12 0.75 0.45 0.25 0.84 0.81 0.77 0.59 0.67 0.68 0.3  0.57 0.34 0.29\n",
      " 0.35 0.4  0.18 0.43 0.44 0.87 0.54 0.46 0.22 0.28 0.86 0.33 0.2  0.39\n",
      " 0.32 0.89 0.26 0.21 0.14 0.23 0.88 0.91 0.15 0.11 0.16 0.1  0.92 0.08\n",
      " 0.06 0.93 0.09 0.07 0.05 0.95 0.94]\n",
      "----------------------------\n",
      "La columna swipe_right_label tiene estos valores únicos:\n",
      "['Optimistic' 'Balanced' 'Cautious']\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "for columna in df:\n",
    "    print(f'La columna {columna} tiene estos valores únicos:')\n",
    "    print(df[columna].unique())\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring                   59.321723\n",
       "diet                        40.694959\n",
       "religion                    33.740366\n",
       "pets                        33.231575\n",
       "drugs                       23.487806\n",
       "sign                        18.443266\n",
       "job                         13.675641\n",
       "education                   11.056618\n",
       "ethnicity                    9.475194\n",
       "smokes                       9.194942\n",
       "body_type                    8.834618\n",
       "drinks                       4.979482\n",
       "speaks                       0.083408\n",
       "height                       0.005005\n",
       "likes_received               0.000000\n",
       "messages_sent_last_week      0.000000\n",
       "profile_views_last_month     0.000000\n",
       "mutual_matches               0.000000\n",
       "essay_word_count             0.000000\n",
       "time_spent_daily             0.000000\n",
       "swipe_right_ratio            0.000000\n",
       "age                          0.000000\n",
       "profile_completeness         0.000000\n",
       "status                       0.000000\n",
       "location                     0.000000\n",
       "last_online                  0.000000\n",
       "income                       0.000000\n",
       "orientation                  0.000000\n",
       "sex                          0.000000\n",
       "swipe_right_label            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.isna().sum() / df.shape[0] * 100).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revision de columnas con Nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring\n",
       "NaN                                        35561\n",
       "doesn't have kids                           7560\n",
       "doesn't have kids, but might want them      3875\n",
       "doesn't have kids, but wants them           3565\n",
       "doesn't want kids                           2927\n",
       "has kids                                    1883\n",
       "has a kid                                   1881\n",
       "doesn't have kids, and doesn't want any     1132\n",
       "has kids, but doesn't want more              442\n",
       "has a kid, but doesn't want more             275\n",
       "has a kid, and might want more               231\n",
       "wants kids                                   225\n",
       "might want kids                              182\n",
       "has kids, and might want more                115\n",
       "has a kid, and wants more                     71\n",
       "has kids, and wants more                      21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reviso columna OFFSPRING \n",
    "\n",
    "df['offspring'].value_counts(dropna=False) #dropna=False -> Te muestra todos los valores, incluyendo cuántos NaN hay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📊 Lo que vemos:\n",
    "Hay 35.561 NaN → eso es un 71% de nulos (algo más alto de lo que veíamos antes, seguramente por limpieza previa).\n",
    "Las respuestas son muy variadas pero algo redundantes, por ejemplo:\n",
    "\"Has A Kid\" y \"Has Kids\" → podrían agruparse\n",
    "\"Doesn't Have Kids\" y \"Doesn't Have Kids, But Wants Them\" → también\n",
    "Algunas respuestas son poco frecuentes\n",
    "\n",
    "🧠 ¿Qué podrías hacer?\n",
    "💡 Opción 1: Agrupar en 3–5 categorías más generales\n",
    "Ejemplo:\n",
    "Categoría original\tNueva categoría propuesta\n",
    "Has Kids / Has A Kid / ...\t               Has kids\n",
    "Doesn’t have kids (todas las variantes)\t   Doesn’t have kids\n",
    "Doesn’t want kids / Doesn’t want more\t   Doesn’t want kids\n",
    "Wants kids / Might want kids\t           Wants kids\n",
    "NaN\t                                       Not declared\n",
    "\n",
    "\n",
    "O ELIMINAR LA COMULNA:\n",
    "\n",
    "df.drop(columns='offspring', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos funcion para agrupar en 4 categorias para hacerlo mas manejable: No declarado, quiere hijos, no quiere hijos, tiene hijos:\n",
    "\n",
    "def agrupar_offspring(valor):\n",
    "    if pd.isna(valor):   # si es NAN (valor nulo) \n",
    "        return 'Not declared'  # devuelve \"no declarado\"\n",
    "    valor = valor.lower()  # convierte el texto en minuscula \n",
    "    if 'has' in valor:\n",
    "        return 'Has kids'\n",
    "    elif 'want' in valor:\n",
    "        return 'Wants kids'\n",
    "    elif \"doesn't have\" in valor:\n",
    "        return \"Doesn't have kids\"\n",
    "    elif \"doesn't want\" in valor:\n",
    "        return \"Doesn't want kids\"\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['offspring_grouped'] = df['offspring'].apply(agrupar_offspring)  # esto crea una nueva columna llamada \"offspring_grouped\" con valores ya agrupados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offspring_grouped\n",
       "Not declared         35561\n",
       "Wants kids           11906\n",
       "Doesn't have kids     7560\n",
       "Has kids              4919\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['offspring_grouped'].value_counts(dropna=False) # reviso como ha quedado.\n",
    "\n",
    "#dropna=False -> Te muestra todos los valores, incluyendo cuántos NaN hay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet\n",
       "NaN                    24395\n",
       "mostly anything        16585\n",
       "anything                6183\n",
       "strictly anything       5113\n",
       "mostly vegetarian       3444\n",
       "mostly other            1007\n",
       "strictly vegetarian      875\n",
       "vegetarian               667\n",
       "strictly other           452\n",
       "mostly vegan             338\n",
       "other                    331\n",
       "strictly vegan           228\n",
       "vegan                    136\n",
       "mostly kosher             86\n",
       "mostly halal              48\n",
       "strictly halal            18\n",
       "strictly kosher           18\n",
       "halal                     11\n",
       "kosher                    11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos los nulos de la columna DIET:\n",
    "\n",
    "df['diet'].value_counts(dropna=False) #dropna=False -> Te muestra todos los valores, incluyendo cuántos NaN hay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos funcion para agrupar en categorias para hacerlo mas manejable: Omnivoro, No declarado, Vegetariano, Otro, Vegano, kosher y Halal.\n",
    "\n",
    "def agrupar_diet(valor):\n",
    "    if pd.isna(valor):\n",
    "        return 'Not declared'\n",
    "    valor = valor.lower()\n",
    "    if 'vegan' in valor:\n",
    "        return 'Vegan'\n",
    "    elif 'vegetarian' in valor:\n",
    "        return 'Vegetarian'\n",
    "    elif 'strictly anything' in valor or 'anything' in valor:\n",
    "        return 'Omnivore'\n",
    "    elif 'kosher' in valor:\n",
    "        return 'Kosher'\n",
    "    elif 'halal' in valor:\n",
    "        return 'Halal'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diet_grouped'] = df['diet'].apply(agrupar_diet) # esto crea una nueva columna llamada \"diet_grouped\" con valores ya agrupados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diet_grouped\n",
       "Omnivore        27881\n",
       "Not declared    24395\n",
       "Vegetarian       4986\n",
       "Other            1790\n",
       "Vegan             702\n",
       "Kosher            115\n",
       "Halal              77\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ 'diet_grouped'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion\n",
       "NaN                                           20226\n",
       "agnosticism                                    2724\n",
       "other                                          2691\n",
       "agnosticism but not too serious about it       2636\n",
       "agnosticism and laughing about it              2496\n",
       "catholicism but not too serious about it       2318\n",
       "atheism                                        2175\n",
       "other and laughing about it                    2119\n",
       "atheism and laughing about it                  2074\n",
       "christianity                                   1957\n",
       "christianity but not too serious about it      1952\n",
       "other but not too serious about it             1554\n",
       "judaism but not too serious about it           1517\n",
       "atheism but not too serious about it           1318\n",
       "catholicism                                    1064\n",
       "christianity and somewhat serious about it      927\n",
       "atheism and somewhat serious about it           848\n",
       "other and somewhat serious about it             846\n",
       "catholicism and laughing about it               726\n",
       "judaism and laughing about it                   681\n",
       "buddhism but not too serious about it           650\n",
       "agnosticism and somewhat serious about it       642\n",
       "judaism                                         612\n",
       "christianity and very serious about it          578\n",
       "atheism and very serious about it               570\n",
       "catholicism and somewhat serious about it       548\n",
       "other and very serious about it                 533\n",
       "buddhism and laughing about it                  466\n",
       "buddhism                                        403\n",
       "christianity and laughing about it              373\n",
       "buddhism and somewhat serious about it          359\n",
       "agnosticism and very serious about it           314\n",
       "judaism and somewhat serious about it           266\n",
       "hinduism but not too serious about it           227\n",
       "hinduism                                        107\n",
       "catholicism and very serious about it           102\n",
       "buddhism and very serious about it               70\n",
       "hinduism and somewhat serious about it           58\n",
       "islam                                            48\n",
       "hinduism and laughing about it                   44\n",
       "islam but not too serious about it               40\n",
       "judaism and very serious about it                22\n",
       "islam and somewhat serious about it              22\n",
       "islam and laughing about it                      16\n",
       "hinduism and very serious about it               14\n",
       "islam and very serious about it                  13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos ahora la columna Religion:\n",
    "\n",
    "df['religion'].value_counts(dropna=False) #dropna=False -> Te muestra todos los valores, incluyendo cuántos NaN hay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos funcion para agrupar en categorias para hacerlo mas manejable: No declarado, Agnostico, Ateo, Cristiano, Judio, Budista, Hindu, Catolico, Musulman, Otros.\n",
    "\n",
    "def agrupar_religion(valor):\n",
    "    if pd.isna(valor):\n",
    "        return 'Not declared'\n",
    "    valor = valor.lower()\n",
    "    if 'agnostic' in valor:\n",
    "        return 'Agnostic'\n",
    "    elif 'atheist' in valor:\n",
    "        return 'Atheist'\n",
    "    elif 'christian' in valor:\n",
    "        return 'Christian'\n",
    "    elif 'jewish' in valor:\n",
    "        return 'Jewish'\n",
    "    elif 'buddhist' in valor:\n",
    "        return 'Buddhist'\n",
    "    elif 'hindu' in valor:\n",
    "        return 'Hindu'\n",
    "    elif 'catholic' in valor:\n",
    "        return 'Catholic'\n",
    "    elif 'muslim' in valor:\n",
    "        return 'Muslim'\n",
    "    else:\n",
    "        return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['religion_grouped'] = df['religion'].apply(agrupar_religion) # esto crea una nueva columna llamada \"religion_grouped\" con valores ya agrupados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "religion_grouped\n",
       "Not declared    20226\n",
       "Other           19913\n",
       "Agnostic         8812\n",
       "Christian        5787\n",
       "Catholic         4758\n",
       "Hindu             450\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['religion_grouped'].value_counts(dropna=False) #dropna=False -> Te muestra todos los valores, incluyendo cuántos NaN hay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pets\n",
       "NaN                                19921\n",
       "likes dogs and likes cats          14814\n",
       "likes dogs                          7224\n",
       "likes dogs and has cats             4313\n",
       "has dogs                            4134\n",
       "has dogs and likes cats             2333\n",
       "likes dogs and dislikes cats        2029\n",
       "has dogs and has cats               1474\n",
       "has cats                            1406\n",
       "likes cats                          1063\n",
       "has dogs and dislikes cats           552\n",
       "dislikes dogs and likes cats         240\n",
       "dislikes dogs and dislikes cats      196\n",
       "dislikes cats                        122\n",
       "dislikes dogs and has cats            81\n",
       "dislikes dogs                         44\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna pets.\n",
    "\n",
    "df['pets'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos funcion para agrupar en categorias para hacerlo mas manejable\n",
    "\n",
    "def agrupar_pets(valor):\n",
    "    if pd.isna(valor):\n",
    "        return 'Not declared'\n",
    "    valor = valor.lower()\n",
    "    if 'dislikes' in valor:\n",
    "        return 'Dislikes pets'\n",
    "    elif 'has dogs and has cats' in valor:\n",
    "        return 'Has pets'\n",
    "    elif 'has dog' in valor:\n",
    "        return 'Has dog'\n",
    "    elif 'has cat' in valor:\n",
    "        return 'Has cat'\n",
    "    elif 'likes dogs' in valor or 'likes cats' in valor:\n",
    "        return 'Likes pets'\n",
    "    else:\n",
    "        return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pets_grouped'] = df['pets'].apply(agrupar_pets)  # esto crea una nueva columna llamada \"pets_grouped\" con valores ya agrupados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pets_grouped\n",
       "Likes pets       23101\n",
       "Not declared     19921\n",
       "Has dog           6467\n",
       "Has cat           5719\n",
       "Dislikes pets     3264\n",
       "Has pets          1474\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['pets_grouped'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drugs\n",
       "never        37724\n",
       "NaN          14080\n",
       "sometimes     7732\n",
       "often          410\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna DRUGS: y la mantenemos igual\n",
    "\n",
    "df['drugs'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign\n",
       "NaN                                              11056\n",
       "gemini and it&rsquo;s fun to think about          1782\n",
       "scorpio and it&rsquo;s fun to think about         1772\n",
       "leo and it&rsquo;s fun to think about             1692\n",
       "libra and it&rsquo;s fun to think about           1649\n",
       "taurus and it&rsquo;s fun to think about          1640\n",
       "cancer and it&rsquo;s fun to think about          1597\n",
       "pisces and it&rsquo;s fun to think about          1592\n",
       "sagittarius and it&rsquo;s fun to think about     1583\n",
       "virgo and it&rsquo;s fun to think about           1574\n",
       "aries and it&rsquo;s fun to think about           1573\n",
       "aquarius and it&rsquo;s fun to think about        1503\n",
       "virgo but it doesn&rsquo;t matter                 1497\n",
       "leo but it doesn&rsquo;t matter                   1457\n",
       "cancer but it doesn&rsquo;t matter                1454\n",
       "gemini but it doesn&rsquo;t matter                1453\n",
       "taurus but it doesn&rsquo;t matter                1450\n",
       "aquarius but it doesn&rsquo;t matter              1408\n",
       "libra but it doesn&rsquo;t matter                 1408\n",
       "capricorn and it&rsquo;s fun to think about       1376\n",
       "sagittarius but it doesn&rsquo;t matter           1375\n",
       "aries but it doesn&rsquo;t matter                 1373\n",
       "capricorn but it doesn&rsquo;t matter             1319\n",
       "pisces but it doesn&rsquo;t matter                1300\n",
       "scorpio but it doesn&rsquo;t matter               1264\n",
       "leo                                               1159\n",
       "libra                                             1098\n",
       "cancer                                            1092\n",
       "virgo                                             1029\n",
       "scorpio                                           1020\n",
       "gemini                                            1013\n",
       "taurus                                            1001\n",
       "aries                                              996\n",
       "pisces                                             992\n",
       "aquarius                                           954\n",
       "sagittarius                                        937\n",
       "capricorn                                          833\n",
       "scorpio and it matters a lot                        78\n",
       "leo and it matters a lot                            66\n",
       "cancer and it matters a lot                         63\n",
       "aquarius and it matters a lot                       63\n",
       "pisces and it matters a lot                         62\n",
       "gemini and it matters a lot                         62\n",
       "libra and it matters a lot                          52\n",
       "taurus and it matters a lot                         49\n",
       "aries and it matters a lot                          47\n",
       "sagittarius and it matters a lot                    47\n",
       "capricorn and it matters a lot                      45\n",
       "virgo and it matters a lot                          41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna SIGN:\n",
    "\n",
    "df['sign'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos funcion para quedarnos solo con el horoscopo principal.\n",
    "\n",
    "def extraer_signo(valor):\n",
    "    if pd.isna(valor):\n",
    "        return 'Not declared'\n",
    "    return valor.split()[0]  # solo se queda con \"Aries\", \"Libra\", etc.\n",
    "\n",
    "df['sign_grouped'] = df['sign'].apply(extraer_signo) # creamos la columna agrupada nueva.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sign_grouped\n",
       "Not declared    11056\n",
       "leo              4374\n",
       "gemini           4310\n",
       "libra            4207\n",
       "cancer           4206\n",
       "virgo            4141\n",
       "taurus           4140\n",
       "scorpio          4134\n",
       "aries            3989\n",
       "pisces           3946\n",
       "sagittarius      3942\n",
       "aquarius         3928\n",
       "capricorn        3573\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sign_grouped'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job\n",
       "NaN                                  8198\n",
       "other                                7589\n",
       "student                              4882\n",
       "science / tech / engineering         4848\n",
       "computer / hardware / software       4709\n",
       "artistic / musical / writer          4439\n",
       "sales / marketing / biz dev          4391\n",
       "medicine / health                    3680\n",
       "education / academia                 3513\n",
       "executive / management               2373\n",
       "banking / financial / real estate    2266\n",
       "entertainment / media                2250\n",
       "law / legal services                 1381\n",
       "hospitality / travel                 1364\n",
       "construction / craftsmanship         1021\n",
       "clerical / administrative             805\n",
       "political / government                708\n",
       "rather not say                        436\n",
       "transportation                        366\n",
       "unemployed                            273\n",
       "retired                               250\n",
       "military                              204\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna JOB: agrupamos para que sea mas clara.\n",
    "\n",
    "df['job'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos funcion para agrupar y reducir las opciones de job.\n",
    "\n",
    "def agrupar_job(valor):\n",
    "    if pd.isna(valor):\n",
    "        return 'Not declared'\n",
    "    valor = valor.lower()\n",
    "    if 'tech' in valor or 'engineering' in valor:\n",
    "        return 'STEM'\n",
    "    elif 'education' in valor:\n",
    "        return 'Education'\n",
    "    elif 'medicine' in valor:\n",
    "        return 'Health'\n",
    "    elif 'student' in valor:\n",
    "        return 'Student'\n",
    "    elif 'art' in valor or 'creative' in valor:\n",
    "        return 'Artistic'\n",
    "    elif 'bank' in valor or 'finance' in valor:\n",
    "        return 'Finance'\n",
    "    elif 'hospitality' in valor or 'travel' in valor:\n",
    "        return 'Services'\n",
    "    elif 'retired' in valor or 'unemployed' in valor:\n",
    "        return 'Not working'\n",
    "    else:\n",
    "        return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_grouped'] = df['job'].apply(agrupar_job) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "job_grouped\n",
       "Other           26233\n",
       "Not declared     8198\n",
       "Student          4882\n",
       "STEM             4848\n",
       "Artistic         4439\n",
       "Health           3680\n",
       "Education        3513\n",
       "Finance          2266\n",
       "Services         1364\n",
       "Not working       523\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['job_grouped'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "graduated from college/university    23959\n",
       "graduated from masters program        8961\n",
       "working on college/university         5712\n",
       "working on masters program            1683\n",
       "graduated from two-year college       1531\n",
       "graduated from high school            1428\n",
       "graduated from ph.d program           1272\n",
       "graduated from law school             1122\n",
       "working on two-year college           1074\n",
       "dropped out of college/university      995\n",
       "working on ph.d program                983\n",
       "college/university                     801\n",
       "graduated from space camp              657\n",
       "dropped out of space camp              523\n",
       "graduated from med school              446\n",
       "working on space camp                  445\n",
       "working on law school                  269\n",
       "two-year college                       222\n",
       "working on med school                  212\n",
       "dropped out of two-year college        191\n",
       "dropped out of masters program         140\n",
       "masters program                        136\n",
       "dropped out of ph.d program            127\n",
       "dropped out of high school             102\n",
       "high school                             96\n",
       "working on high school                  87\n",
       "space camp                              58\n",
       "ph.d program                            26\n",
       "law school                              19\n",
       "dropped out of law school               18\n",
       "dropped out of med school               12\n",
       "med school                              11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna EDUCATION:\n",
    "\n",
    "df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎓 ¿Qué vemos?\n",
    "Hay muchos valores con formato largo: \"Graduated From...\", \"Working On...\", \"Dropped Out Of...\".\n",
    "Aparecen muchas etapas educativas repetidas: \"college\", \"masters\", \"ph.d\", \"law school\", \"med school\", etc.\n",
    "Hay valores graciosos como \"space camp\" que seguramente son broma 😅\n",
    "🧠 ¿Qué puedes hacer?\n",
    "Podemos agrupar este campo en niveles educativos estándar, algo así:\n",
    "Agrupación propuesta\tValores incluidos (ejemplos)\n",
    "High school\t     ->             Graduated/Working/Dropped Out of High School\n",
    "College\t         ->             College/University + Two-Year College\n",
    "Masters          ->         \tMasters Program\n",
    "PhD\t               ->         Ph.D Program\n",
    "Professional School\t  ->      Law School, Med School\n",
    "Other\t               ->      Space Camp, etc.\n",
    "Not declared\t       ->        NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_education(valor):\n",
    "    if pd.isna(valor):\n",
    "        return 'Not declared'\n",
    "    valor = valor.lower()\n",
    "    if 'high school' in valor:\n",
    "        return 'High school'\n",
    "    elif 'two-year college' in valor or 'college' in valor or 'university' in valor:\n",
    "        return 'College'\n",
    "    elif 'masters' in valor:\n",
    "        return 'Masters'\n",
    "    elif 'ph.d' in valor:\n",
    "        return 'PhD'\n",
    "    elif 'law school' in valor or 'med school' in valor:\n",
    "        return 'Professional School'\n",
    "    elif 'space camp' in valor:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['education_grouped'] = df['education'].apply(agrupar_education)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education_grouped\n",
       "College                34485\n",
       "Masters                10920\n",
       "Not declared            6628\n",
       "PhD                     2408\n",
       "Professional School     2109\n",
       "High school             1713\n",
       "Other                   1683\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education_grouped'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "white                                                                 32831\n",
       "asian                                                                  6134\n",
       "NaN                                                                    5680\n",
       "hispanic / latin                                                       2823\n",
       "black                                                                  2008\n",
       "                                                                      ...  \n",
       "middle eastern, indian, white                                             1\n",
       "asian, middle eastern, black, white, other                                1\n",
       "asian, middle eastern, indian, hispanic / latin, white, other             1\n",
       "black, native american, indian, pacific islander, hispanic / latin        1\n",
       "asian, black, indian                                                      1\n",
       "Name: count, Length: 218, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna ETNIA\n",
    "\n",
    "df['ethnicity'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos funcion para que coja solo un valor en la columna.\n",
    "\n",
    "def agrupar_ethnicity(valor):\n",
    "    if pd.isna(valor):\n",
    "        return 'Not declared'\n",
    "    return valor.split(',')[0].strip().capitalize() \n",
    "\n",
    "# valor.split(',')[0] -> convierte el texto en una lista separada por comas, para quedarnos solo con el primer item que sale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ethnicity_grouped'] = df['ethnicity'].apply(agrupar_ethnicity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity_grouped\n",
       "White               33472\n",
       "Asian                8205\n",
       "Not declared         5680\n",
       "Hispanic / latin     4379\n",
       "Black                3071\n",
       "Other                1706\n",
       "Indian               1196\n",
       "Middle eastern        811\n",
       "Pacific islander      717\n",
       "Native american       709\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ethnicity_grouped'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "smokes\n",
       "no                43896\n",
       "NaN                5512\n",
       "sometimes          3787\n",
       "when drinking      3040\n",
       "yes                2231\n",
       "trying to quit     1480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna Smokes: la mantenemos\n",
    "\n",
    "df['smokes'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_type\n",
       "average           14652\n",
       "fit               12711\n",
       "athletic          11819\n",
       "NaN                5296\n",
       "thin               4711\n",
       "curvy              3924\n",
       "a little extra     2629\n",
       "skinny             1777\n",
       "full figured       1009\n",
       "overweight          444\n",
       "jacked              421\n",
       "used up             355\n",
       "rather not say      198\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna BODY_TYPE:\n",
    "\n",
    "df['body_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recomendación: Agrupar para hacerlo más manejable\n",
    "Como te propuse antes, puedes reducir a:\n",
    "Athletic → fit, athletic, jacked\n",
    "Average → average, a little extra\n",
    "Curvy/Plus → curvy, full figured, overweight\n",
    "Slim → thin, skinny\n",
    "Not declared → NaN y rather not say\n",
    "Other → used up u otros residuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos funcion para agrupar datos:\n",
    "\n",
    "def agrupar_body_type(valor):\n",
    "    if pd.isna(valor) or 'rather not say' in str(valor).lower():\n",
    "        return 'Not declared'\n",
    "    valor = valor.lower()\n",
    "    if valor in ['fit', 'athletic', 'jacked']:\n",
    "        return 'Athletic'\n",
    "    elif valor in ['average', 'a little extra']:\n",
    "        return 'Average'\n",
    "    elif valor in ['curvy', 'full figured', 'overweight']:\n",
    "        return 'Curvy/Plus'\n",
    "    elif valor in ['thin', 'skinny']:\n",
    "        return 'Slim'\n",
    "    elif valor in ['used up']:\n",
    "        return 'Other'\n",
    "    else:\n",
    "        return 'Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['body_type_grouped'] = df['body_type'].apply(agrupar_body_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body_type_grouped\n",
       "Athletic        24951\n",
       "Average         17281\n",
       "Slim             6488\n",
       "Not declared     5494\n",
       "Curvy/Plus       5377\n",
       "Other             355\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['body_type_grouped'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drinks\n",
       "socially       41780\n",
       "rarely          5957\n",
       "often           5164\n",
       "not at all      3267\n",
       "NaN             2985\n",
       "very often       471\n",
       "desperately      322\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna DRINKS: no se modifica\n",
    "\n",
    "df['drinks'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaks\n",
       "english                                                                21828\n",
       "english (fluently)                                                      6628\n",
       "english (fluently), spanish (poorly)                                    2059\n",
       "english (fluently), spanish (okay)                                      1917\n",
       "english (fluently), spanish (fluently)                                  1288\n",
       "                                                                       ...  \n",
       "english (fluently), urdu (poorly), japanese (poorly), french (okay)        1\n",
       "english, spanish, hindi, c++                                               1\n",
       "english (fluently), japanese (okay), thai (okay), chinese (poorly)         1\n",
       "english (fluently), french (okay), italian (okay), hebrew (okay)           1\n",
       "english (fluently), french, farsi                                          1\n",
       "Name: count, Length: 7648, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos la columna SPEAKS:\n",
    "\n",
    "df['speaks'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos funcion para quedarnos con el idioma principal:\n",
    "\n",
    "def extraer_idioma_principal(valor):\n",
    "    if pd.isna(valor):\n",
    "        return 'Not declared'\n",
    "    return valor.split(',')[0].split('(')[0].strip().capitalize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['speaks_primary'] = df['speaks'].apply(extraer_idioma_principal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaks_primary\n",
       "English         59892\n",
       "Not declared       50\n",
       "French              2\n",
       "Afrikaans           1\n",
       "Portuguese          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['speaks_primary'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalización de revisión de los nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos una funcion de limpieza de texto.\n",
    "\n",
    "def limpiar_texto(col):\n",
    "    return col.str.strip().str.title() # .strip -> elimino espacios  // paso a Title para respetar los nombres propios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['status',\n",
       " 'sex',\n",
       " 'orientation',\n",
       " 'body_type',\n",
       " 'diet',\n",
       " 'drinks',\n",
       " 'drugs',\n",
       " 'education',\n",
       " 'ethnicity',\n",
       " 'job',\n",
       " 'last_online',\n",
       " 'location',\n",
       " 'offspring',\n",
       " 'pets',\n",
       " 'religion',\n",
       " 'sign',\n",
       " 'smokes',\n",
       " 'speaks',\n",
       " 'swipe_right_label']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicamos la funcion a mis columnas categoricas.\n",
    "\n",
    "for col in col_objects:\n",
    "    df[col] = limpiar_texto(df[col])\n",
    "\n",
    "col_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardamos el dataset limpio :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. eliminamos las columnas originales que ya no necesitamos.\n",
    "\n",
    "df.drop(columns=[\n",
    "    'offspring', 'diet', 'religion', 'pets', 'education', 'ethnicity',\n",
    "    'body_type', 'job', 'sign', 'speaks'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el dataset limpio a csv\n",
    "\n",
    "df.to_csv(\"okcupid_limpio_final.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
